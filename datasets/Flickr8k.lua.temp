------------------------------------------------------------------------
--[[ Flickr8k ]]--
-- A image caption dataset.
-- Dataformat: 1 image / 5 sentences
------------------------------------------------------------------------

--require("mobdebug").start()
require 'hdf5' -- read .h5 file format
require 'torchx' -- for paths.indexdir
require 'lfs'
require 'dp'

---------------------------------------------------------------------------
--- First, let's try to convert the Flickr8k dataset into dp.dataset format
--- Don't know how to deal with the sentence yet.
--- Should the sentence be dealt as multi-labels? Or ?
---------------------------------------------------------------------------


local Flickr8k, DataSource = torch.class("Flickr8k", "dp.DataSource")
Flickr8k.isFlickr8k = true

Flickr8k._name = 'flickr8k'
Flickr8k._image_size = {3, 256, 256}
Flickr8k._image_axes = 'bchw'
Flickr8k._feature_size = 3*256*256

function Flickr8k:__init(config)
    print ("entering __init")
    config = config or {}
    print ("flickr8k config:", config)
    assert(torch.type(config) == 'table' and not config[1],
        "Constructor requires key-value arguments")
    local args, load_all, input_preprocess, target_preprocess
    args, self._valid_ratio, self._data_file, self._test_file,
    self._data_path, self._scale, self._binarize, self._shuffle,
    self._download_url, load_all, input_preprocess,
    target_preprocess
    = xlua.unpack(
        {config},
        'Flickr8k',
        {arg='valid_ratio', type='number', default=0,
            help='proportion of training set to use for cross-validation.'},
        {arg='data_file', type='string', default='data.h5',
            help='images info, e.g., Nx3x256x256 images and labels, etc.'},
        {arg='caption_file', type='string', default='flickr8k_100_set.json',
            help='ix_to_word etc. information'},
        {arg='data_path', type='string', default=dp.DATA_DIR,
            help='path to data repository'},
        {arg='scale', type='table',
            help='bounds to scale the values between. [Default={0,1}]'},
        {arg='binarize', type='boolean',
            help='binarize the inputs (0s and 1s)', default=false},
        {arg='shuffle', type='boolean',
            help='shuffle different sets', default=false},
        {arg='download_url', type='string',
            default='#TODO',
            help='URL from which to download dataset if not found on disk.'},
        {arg='load_all', type='boolean',
            help='Load all datasets : train, valid, test.', default=true},
        {arg='input_preprocess', type='table | dp.Preprocess',
            help='to be performed on set inputs, measuring statistics ' ..
                    '(fitting) on the train_set only, and reusing these to ' ..
                    'preprocess the valid_set and test_set.'},
        {arg='target_preprocess', type='table | dp.Preprocess',
            help='to be performed on set targets, measuring statistics ' ..
                    '(fitting) on the train_set only, and reusing these to ' ..
                    'preprocess the valid_set and test_set.'}
    )
    if (self._scale == nil) then
        self._scale = {0,1}
    end
    print ("flickr8k load_all: ", load_all)
    if load_all then
	self:setup()
	print ('debug')
        self:loadTrainValid()
        self:loadTest()
    end
    DataSource.__init(self, {
        train_set=self:trainSet(), valid_set=self:validSet(),
        test_set=self:testSet(), input_preprocess=input_preprocess,
        target_preprocess=target_preprocess
    })
end

function Flickr8k:setup()
    -- 1. load the images, and the caption sentences
    -- pre-prepared with neuraltalk2/prepo.py, to create lua-readable data

    -- data.h5 file format:
    --  -> 'images': (100, 3, 256, 256), contains 100 resized (3x256x256) images. Note: image 100 is black??
    --  -> 'label_end_ix': 1-indexed numbers, 1-100, no idea what it is for, for now.
    --  -> 'label_length': the sentence length of each image captioned
    --  -> 'label_start_ix': again, 1-indexed numbers, 1-100, no idea what it is for
    --  -> 'labels': (100, 16), 100 images; 16 as the longest sentence;
    --  ->      each containes a sequence of numbers, representing the numbered word

    -- #TODO(Completed): add assertion to make sure file exists

    print ('Preparing Flickr8k into dp.DataSource format ...')

    print ('Loading flickr8k data.h5 file ...')
    --h5_file_path = datapath..'/'..'data.h5'
    print (self._data_file)
    if utils.exists(self._data_file) then print ('Done.') else return end
    
    local h5_file = hdf5.open(h5_file_path)
    local images = h5_file:read('/images'):all() -- read all 100 images, access via images[i] for image i
    local sentences = h5_file:read('/labels'):all() -- read all 100 sentences, access via sentences[i] for image i
    h5_file:close()

    -- 2. load the word-number mapping json file
    -- pre-prepared with neuraltalk2/prepo.py

    -- data.json file format:
    --  -> 'images': containes info of the 100 images, 100 x {'flie_path', 'split'}
    --       -> 'file_path': string, the filename, eg. '1597557856_30640e0b43.jpg'
    --       -> 'split': string, 'train', 'validation', or 'test' split
    --  -> 'ix_to_word': the mapping from number to word, eg. 101 is 'cigarettes'

    -- #TODO(Completed): add assertion to make sure file exists --- Completed

    print ('Loading flickr8k data.json file ...')
    json_file_path = datapath..'/'..'data.json'
    if utils.exists(json_file_path) then print ('Done.') else return end -- check whether file exists
    local json_file = io.open(json_file_path)
    local text = json_file:read()
    local cjson = require 'cjson' -- read .json file format
    local json_file_contents = cjson.decode(text)
    local ix_to_word = json_file_contents.ix_to_word
    local images_info = json_file_contents.images
    json_file:close()

    -- put the images, sentences, images_info, and ix_to_word all together into a flickr8k dataset
    self._flickr8k = {images, sentences, images_info, ix_to_word}

end

function Flickr8k:loadTrainValid()
    --Data will contain a tensor where each row is an example, and where
    --the last column contains the target class.
    local data = self:loadData(self._train_file, self._download_url)
    -- train
    local start = 1
    local size = math.floor(data[1]:size(1)*(1-self._valid_ratio))
    self:trainSet(
        self:createDataSet(
            data[1]:narrow(1, start, size), data[2]:narrow(1, start, size),
            'train'
        )
    )
    -- valid
    if self._valid_ratio == 0 then
        print"Warning : No Valid Set due to valid_ratio == 0"
        return
    end
    start = size
    size = data[1]:size(1)-start
    self:validSet(
        self:createDataSet(
            data[1]:narrow(1, start, size), data[2]:narrow(1, start, size),
            'valid'
        )
    )
    return self:trainSet(), self:validSet()
end

function Flickr8k:loadTest()
    local test_data = self:loadData(self._test_file, self._download_url)
    --print (#test_data[1][1])
    --local image = require "image"
    --test_lc = test_data[1][1]:clone()
    --test_lc = test_lc:resize(1,28,28)
    --image.display(test_lc)
    self:testSet(
        self:createDataSet(test_data[1], test_data[2], 'test')
    )
    return self:testSet()
end

--Creates an Flickr8k Dataset out of inputs, targets and which_set
function Flickr8k:createDataSet(inputs, targets, which_set)
    if self._shuffle then
        local indices = torch.randperm(inputs:size(1)):long()
        inputs = inputs:index(1, indices)
        targets = targets:index(1, indices)
    end
    if self._binarize then
        DataSource.binarize(inputs, 128)
    end
    if self._scale and not self._binarize then
        DataSource.rescale(inputs, self._scale[1], self._scale[2])
    end
    -- class 0 will have index 1, class 1 index 2, and so on.
    targets:add(1)
    -- construct inputs and targets dp.Views
    local input_v, target_v = dp.ImageView(), dp.ClassView()
    input_v:forward(self._image_axes, inputs)
    target_v:forward('b', targets)
    target_v:setClasses(self._classes)
    -- construct dataset
    local ds = dp.DataSet{inputs=input_v,targets=target_v,which_set=which_set}
    ds:ioShapes('bhwc', 'b')
    return ds
end

function Flickr8k:loadData(file_name, download_url)
    local path = DataSource.getDataPath{
        name=self._name, url=download_url,
        decompress_file=file_name,
        data_dir=self._data_path
    }
    -- backwards compatible with old binary format
    local status, data = pcall(function() return torch.load(path, "ascii") end)
    if not status then
        return torch.load(path, "binary")
    end
    return data
end

